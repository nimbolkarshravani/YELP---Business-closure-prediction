{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx-Dnw0UsPTQ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "import json\n",
        "from re import sub\n",
        "from time import time \n",
        "from unidecode import unidecode\n",
        "from gensim.models import Word2Vec\n",
        "from collections import defaultdict\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjW7UgmPsPTU"
      },
      "outputs": [],
      "source": [
        "df=pd.read_json('yelp_academic_dataset_review.json',lines=True,nrows=300000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA-pPvrbsPTV"
      },
      "outputs": [],
      "source": [
        "df2=pd.read_json(\"yelp_academic_dataset_business (1).json\",lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjoYLJtMsPTW",
        "outputId": "f6c11475-9ef8-4311-df48-8a478290e493"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars_x</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>name</th>\n",
              "      <th>...</th>\n",
              "      <th>state</th>\n",
              "      <th>postal_code</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>stars_y</th>\n",
              "      <th>review_count</th>\n",
              "      <th>is_open</th>\n",
              "      <th>attributes</th>\n",
              "      <th>categories</th>\n",
              "      <th>hours</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
              "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>If you decide to eat here, just be aware it is...</td>\n",
              "      <td>2018-07-07 22:09:11</td>\n",
              "      <td>Turning Point of North Wales</td>\n",
              "      <td>...</td>\n",
              "      <td>PA</td>\n",
              "      <td>19454</td>\n",
              "      <td>40.210196</td>\n",
              "      <td>-75.223639</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169</td>\n",
              "      <td>1</td>\n",
              "      <td>{'NoiseLevel': 'u'average'', 'HasTV': 'False',...</td>\n",
              "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
              "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VJxlBnJmCDIy8DFG0kjSow</td>\n",
              "      <td>Iaee7y6zdSB3B-kRCo4z1w</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>This is the second time we tried turning point...</td>\n",
              "      <td>2017-05-13 17:06:55</td>\n",
              "      <td>Turning Point of North Wales</td>\n",
              "      <td>...</td>\n",
              "      <td>PA</td>\n",
              "      <td>19454</td>\n",
              "      <td>40.210196</td>\n",
              "      <td>-75.223639</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169</td>\n",
              "      <td>1</td>\n",
              "      <td>{'NoiseLevel': 'u'average'', 'HasTV': 'False',...</td>\n",
              "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
              "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S6pQZQocMB1WHMjTRbt77A</td>\n",
              "      <td>ejFxLGqQcWNLdNByJlIhnQ</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>The place is cute and the staff was very frien...</td>\n",
              "      <td>2017-08-08 00:58:18</td>\n",
              "      <td>Turning Point of North Wales</td>\n",
              "      <td>...</td>\n",
              "      <td>PA</td>\n",
              "      <td>19454</td>\n",
              "      <td>40.210196</td>\n",
              "      <td>-75.223639</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169</td>\n",
              "      <td>1</td>\n",
              "      <td>{'NoiseLevel': 'u'average'', 'HasTV': 'False',...</td>\n",
              "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
              "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WqgTKVqWVHDHjnjEsBvUgg</td>\n",
              "      <td>f7xa0p_1V9lx53iIGN5Sug</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>We came on a Saturday morning after waiting a ...</td>\n",
              "      <td>2017-11-19 02:20:23</td>\n",
              "      <td>Turning Point of North Wales</td>\n",
              "      <td>...</td>\n",
              "      <td>PA</td>\n",
              "      <td>19454</td>\n",
              "      <td>40.210196</td>\n",
              "      <td>-75.223639</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169</td>\n",
              "      <td>1</td>\n",
              "      <td>{'NoiseLevel': 'u'average'', 'HasTV': 'False',...</td>\n",
              "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
              "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M0wzFFb7pefOPcxeRVbLag</td>\n",
              "      <td>dCooFVCk8M1nVaQqcfTL3Q</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Mediocre at best. The decor is very nice, and ...</td>\n",
              "      <td>2017-09-09 17:49:47</td>\n",
              "      <td>Turning Point of North Wales</td>\n",
              "      <td>...</td>\n",
              "      <td>PA</td>\n",
              "      <td>19454</td>\n",
              "      <td>40.210196</td>\n",
              "      <td>-75.223639</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169</td>\n",
              "      <td>1</td>\n",
              "      <td>{'NoiseLevel': 'u'average'', 'HasTV': 'False',...</td>\n",
              "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
              "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id                 user_id             business_id  \\\n",
              "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "1  VJxlBnJmCDIy8DFG0kjSow  Iaee7y6zdSB3B-kRCo4z1w  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "2  S6pQZQocMB1WHMjTRbt77A  ejFxLGqQcWNLdNByJlIhnQ  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "3  WqgTKVqWVHDHjnjEsBvUgg  f7xa0p_1V9lx53iIGN5Sug  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "4  M0wzFFb7pefOPcxeRVbLag  dCooFVCk8M1nVaQqcfTL3Q  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "\n",
              "   stars_x  useful  funny  cool  \\\n",
              "0        3       0      0     0   \n",
              "1        2       0      0     0   \n",
              "2        4       2      0     1   \n",
              "3        3       0      0     0   \n",
              "4        2       0      0     0   \n",
              "\n",
              "                                                text                date  \\\n",
              "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11   \n",
              "1  This is the second time we tried turning point... 2017-05-13 17:06:55   \n",
              "2  The place is cute and the staff was very frien... 2017-08-08 00:58:18   \n",
              "3  We came on a Saturday morning after waiting a ... 2017-11-19 02:20:23   \n",
              "4  Mediocre at best. The decor is very nice, and ... 2017-09-09 17:49:47   \n",
              "\n",
              "                           name  ... state postal_code   latitude  longitude  \\\n",
              "0  Turning Point of North Wales  ...    PA       19454  40.210196 -75.223639   \n",
              "1  Turning Point of North Wales  ...    PA       19454  40.210196 -75.223639   \n",
              "2  Turning Point of North Wales  ...    PA       19454  40.210196 -75.223639   \n",
              "3  Turning Point of North Wales  ...    PA       19454  40.210196 -75.223639   \n",
              "4  Turning Point of North Wales  ...    PA       19454  40.210196 -75.223639   \n",
              "\n",
              "   stars_y  review_count  is_open  \\\n",
              "0      3.0           169        1   \n",
              "1      3.0           169        1   \n",
              "2      3.0           169        1   \n",
              "3      3.0           169        1   \n",
              "4      3.0           169        1   \n",
              "\n",
              "                                          attributes  \\\n",
              "0  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
              "1  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
              "2  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
              "3  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
              "4  {'NoiseLevel': 'u'average'', 'HasTV': 'False',...   \n",
              "\n",
              "                                          categories  \\\n",
              "0  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
              "1  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
              "2  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
              "3  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
              "4  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
              "\n",
              "                                               hours  \n",
              "0  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...  \n",
              "1  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...  \n",
              "2  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...  \n",
              "3  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...  \n",
              "4  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file=pd.merge(df, df2, on='business_id', how='inner')\n",
        "file.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4T_L4HfsPTX"
      },
      "outputs": [],
      "source": [
        "# file = pd.read_csv(\"polish_sentiment_dataset.csv\")\n",
        "# file_cleaned = file.dropna().drop_duplicates().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9j_ZyjzsPTY"
      },
      "outputs": [],
      "source": [
        "file=file[['review_id','business_id','text']]\n",
        "file_cleaned = file.dropna().drop_duplicates().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkqPFwzWsPTY",
        "outputId": "5f907719-28a3-4efd-f12f-6f2472036fdf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>If you decide to eat here, just be aware it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VJxlBnJmCDIy8DFG0kjSow</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>This is the second time we tried turning point...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S6pQZQocMB1WHMjTRbt77A</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>The place is cute and the staff was very frien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WqgTKVqWVHDHjnjEsBvUgg</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>We came on a Saturday morning after waiting a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M0wzFFb7pefOPcxeRVbLag</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>Mediocre at best. The decor is very nice, and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id             business_id  \\\n",
              "0  KU_O5udG6zpxOg-VcAEodg  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "1  VJxlBnJmCDIy8DFG0kjSow  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "2  S6pQZQocMB1WHMjTRbt77A  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "3  WqgTKVqWVHDHjnjEsBvUgg  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "4  M0wzFFb7pefOPcxeRVbLag  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "\n",
              "                                                text  \n",
              "0  If you decide to eat here, just be aware it is...  \n",
              "1  This is the second time we tried turning point...  \n",
              "2  The place is cute and the staff was very frien...  \n",
              "3  We came on a Saturday morning after waiting a ...  \n",
              "4  Mediocre at best. The decor is very nice, and ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvtmZUNcsPTZ"
      },
      "outputs": [],
      "source": [
        "# file_cleaned.rate.value_counts()/len(file_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np1NXelxsPTZ"
      },
      "outputs": [],
      "source": [
        "# file_cleaned[file_cleaned.rate==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAzEJfCfsPTZ"
      },
      "outputs": [],
      "source": [
        "# file_cleaned = file_cleaned[file_cleaned.rate!=0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTmYyE-AsPTa"
      },
      "outputs": [],
      "source": [
        "# file_cleaned.rate.value_counts()/len(file_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdozzk4WsPTa"
      },
      "outputs": [],
      "source": [
        "def text_to_word_list(text, remove_polish_letters):\n",
        "    ''' Pre process and convert texts to a list of words \n",
        "    method inspired by method from eliorc github repo: https://github.com/eliorc/Medium/blob/master/MaLSTM.ipynb'''\n",
        "    text = remove_polish_letters(text)\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
        "    text = sub(r\"\\+\", \" plus \", text)\n",
        "    text = sub(r\",\", \" \", text)\n",
        "    text = sub(r\"\\.\", \" \", text)\n",
        "    text = sub(r\"!\", \" ! \", text)\n",
        "    text = sub(r\"\\?\", \" ? \", text)\n",
        "    text = sub(r\"'\", \" \", text)\n",
        "    text = sub(r\":\", \" : \", text)\n",
        "    text = sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh-j_x0ssPTa"
      },
      "outputs": [],
      "source": [
        "file_cleaned.text = file_cleaned.text.apply(lambda x: text_to_word_list(x, unidecode))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks9egRF7sPTb"
      },
      "outputs": [],
      "source": [
        "file_model = file_cleaned.copy()\n",
        "file_model = file_model[file_model.text.str.len()>1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgZSedWnsPTb",
        "outputId": "600e208b-8ea9-433e-a830-299976843b4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:05:41: collecting all words and their counts\n",
            "INFO - 15:05:41: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 15:05:46: PROGRESS: at sentence #50000, processed 5315794 words and 890461 word types\n",
            "INFO - 15:05:52: PROGRESS: at sentence #100000, processed 10569388 words and 1430856 word types\n",
            "INFO - 15:05:57: PROGRESS: at sentence #150000, processed 15894822 words and 1896994 word types\n",
            "INFO - 15:06:03: PROGRESS: at sentence #200000, processed 21125310 words and 2314654 word types\n",
            "INFO - 15:06:10: PROGRESS: at sentence #250000, processed 26348221 words and 2719098 word types\n",
            "INFO - 15:06:16: collected 3145940 token types (unigram + bigrams) from a corpus of 31573621 words and 299993 sentences\n",
            "INFO - 15:06:16: merged Phrases<3145940 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
            "INFO - 15:06:16: Phrases lifecycle event {'msg': 'built Phrases<3145940 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000> in 34.04s', 'datetime': '2022-11-30T15:06:16.025000', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'created'}\n",
            "INFO - 15:06:16: exporting phrases from Phrases<3145940 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
            "INFO - 15:06:22: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<81617 phrases, min_count=1, threshold=10.0> from Phrases<3145940 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000> in 6.60s', 'datetime': '2022-11-30T15:06:22.627137', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'created'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'second',\n",
              " 'time',\n",
              " 'we',\n",
              " 'tried',\n",
              " 'turning_point',\n",
              " 'at',\n",
              " 'this',\n",
              " 'location',\n",
              " 'the',\n",
              " 'first',\n",
              " 'time',\n",
              " 'we',\n",
              " 'had',\n",
              " 'a',\n",
              " 'long',\n",
              " 'wait',\n",
              " 'for',\n",
              " 'food',\n",
              " 'after',\n",
              " 'ordering',\n",
              " 'this',\n",
              " 'time',\n",
              " 'we',\n",
              " 'had',\n",
              " 'an',\n",
              " 'even',\n",
              " 'longer',\n",
              " 'wait',\n",
              " 'of',\n",
              " 'over',\n",
              " '40_minutes',\n",
              " 'i',\n",
              " 'had',\n",
              " 'the',\n",
              " 'omelette',\n",
              " 'skillet',\n",
              " 'and',\n",
              " 'there',\n",
              " 'was',\n",
              " 'hardly_any',\n",
              " 'egg',\n",
              " 'in',\n",
              " 'it',\n",
              " 'i',\n",
              " 'felt_like',\n",
              " 'i',\n",
              " 'was',\n",
              " 'eating',\n",
              " 'chopped_onions',\n",
              " 'and',\n",
              " 'chopped_tomatoes',\n",
              " 'my',\n",
              " 'wife',\n",
              " 'had',\n",
              " 'a',\n",
              " 'blt',\n",
              " 'and',\n",
              " 'had',\n",
              " 'a',\n",
              " 'hard',\n",
              " 'time',\n",
              " 'finding',\n",
              " 'the',\n",
              " 'tomato',\n",
              " 'and',\n",
              " 'the',\n",
              " 'avocado',\n",
              " 'that',\n",
              " 'was',\n",
              " 'supposed',\n",
              " 'be',\n",
              " 'on',\n",
              " 'it',\n",
              " 'overall',\n",
              " 'the',\n",
              " 'experience',\n",
              " 'was',\n",
              " 'stressful',\n",
              " 'mainly_because',\n",
              " 'of',\n",
              " 'the',\n",
              " 'long',\n",
              " 'wait']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent = [row for row in file_model.text]\n",
        "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
        "bigram = Phraser(phrases)\n",
        "sentences = bigram[sent]\n",
        "sentences[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9unIQFysPTb"
      },
      "source": [
        "- min count = 3 - remove most unusual words from training embeddings, like words 'ssssuuuuuuuppppppeeeeeerrrr', which actually stands for 'super', and doesn't need additional training\n",
        "- window = 4 - Word2Vec model will learn to predict given word from up to 4 words to the left, and up to 4 words to the right\n",
        "- vector_size = 300 - size of hidden layer used to predict surroundings of embedded word, which also stands for dimensions of trained embeddings\n",
        "- sample = 1e-5 - probability baseline for subsampling most frequent words from surrounding of embedded word\n",
        "- negative = 20 - number of negative (ones that shouldn't have been predicted while modeling selected pair of words) words that will have their corresponding weights updated while training on specific training example, along with positive word "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Edkn6JRKsPTd",
        "outputId": "72a5f409-3308-45bd-d8f7-5afdb897ba5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:06:22: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2022-11-30T15:06:22.678002', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'created'}\n",
            "INFO - 15:06:22: collecting all words and their counts\n",
            "INFO - 15:06:22: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 15:06:29: PROGRESS: at sentence #50000, processed 5014215 words, keeping 76960 word types\n",
            "INFO - 15:06:32: PROGRESS: at sentence #100000, processed 9978328 words, keeping 112729 word types\n",
            "INFO - 15:06:36: PROGRESS: at sentence #150000, processed 15012098 words, keeping 140468 word types\n",
            "INFO - 15:06:40: PROGRESS: at sentence #200000, processed 19963118 words, keeping 163685 word types\n",
            "INFO - 15:06:44: PROGRESS: at sentence #250000, processed 24911338 words, keeping 184473 word types\n",
            "INFO - 15:06:49: collected 205387 word types from a corpus of 29868966 raw words and 299993 sentences\n",
            "INFO - 15:06:49: Creating a fresh vocabulary\n",
            "INFO - 15:06:52: Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 92528 unique words (45.05% of original 205387, drops 112859)', 'datetime': '2022-11-30T15:06:52.346691', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
            "INFO - 15:06:52: Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 29714340 word corpus (99.48% of original 29868966, drops 154626)', 'datetime': '2022-11-30T15:06:52.357049', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
            "INFO - 15:06:52: deleting the raw counts dictionary of 205387 items\n",
            "INFO - 15:06:53: sample=1e-05 downsamples 2396 most-common words\n",
            "INFO - 15:06:53: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 6611927.2241425 word corpus (22.3%% of prior 29714340)', 'datetime': '2022-11-30T15:06:53.306639', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
            "INFO - 15:06:54: estimated required memory for 92528 words and 300 dimensions: 268331200 bytes\n",
            "INFO - 15:06:54: resetting layer weights\n",
            "INFO - 15:06:54: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-30T15:06:54.489826', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'build_vocab'}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.53 mins\n"
          ]
        }
      ],
      "source": [
        "w2v_model = Word2Vec(min_count=3,\n",
        "                     window=4,\n",
        "                     vector_size=300,\n",
        "                     sample=1e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=multiprocessing.cpu_count()-1)\n",
        "\n",
        "start = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=50000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuJ9j2m0sPTd",
        "outputId": "367edc0f-25c2-4aec-dd05-c5da0ff76a4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:07:01: Word2Vec lifecycle event {'msg': 'training model with 7 workers on 92528 vocabulary and 300 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4 shrink_windows=True', 'datetime': '2022-11-30T15:07:01.943258', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'train'}\n",
            "INFO - 15:07:03: EPOCH 0 - PROGRESS: at 0.92% examples, 54820 words/s, in_qsize 5, out_qsize 9\n",
            "INFO - 15:07:04: EPOCH 0 - PROGRESS: at 3.15% examples, 97997 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:07:05: EPOCH 0 - PROGRESS: at 5.10% examples, 105833 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:07:06: EPOCH 0 - PROGRESS: at 7.10% examples, 111997 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:07:09: EPOCH 0 - PROGRESS: at 9.81% examples, 89325 words/s, in_qsize 14, out_qsize 2\n",
            "INFO - 15:07:10: EPOCH 0 - PROGRESS: at 13.92% examples, 109135 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:07:11: EPOCH 0 - PROGRESS: at 15.52% examples, 107114 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:07:12: EPOCH 0 - PROGRESS: at 16.19% examples, 101128 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:13: EPOCH 0 - PROGRESS: at 19.51% examples, 110400 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:07:14: EPOCH 0 - PROGRESS: at 23.65% examples, 121744 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:07:15: EPOCH 0 - PROGRESS: at 27.52% examples, 131958 words/s, in_qsize 10, out_qsize 6\n",
            "INFO - 15:07:16: EPOCH 0 - PROGRESS: at 31.58% examples, 141012 words/s, in_qsize 6, out_qsize 9\n",
            "INFO - 15:07:17: EPOCH 0 - PROGRESS: at 35.43% examples, 147795 words/s, in_qsize 9, out_qsize 3\n",
            "INFO - 15:07:18: EPOCH 0 - PROGRESS: at 39.55% examples, 155073 words/s, in_qsize 12, out_qsize 0\n",
            "INFO - 15:07:19: EPOCH 0 - PROGRESS: at 42.45% examples, 157441 words/s, in_qsize 7, out_qsize 2\n",
            "INFO - 15:07:20: EPOCH 0 - PROGRESS: at 45.94% examples, 161132 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:07:21: EPOCH 0 - PROGRESS: at 49.89% examples, 166316 words/s, in_qsize 10, out_qsize 0\n",
            "INFO - 15:07:22: EPOCH 0 - PROGRESS: at 53.57% examples, 169828 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:23: EPOCH 0 - PROGRESS: at 57.44% examples, 173243 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:07:24: EPOCH 0 - PROGRESS: at 60.69% examples, 174780 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:25: EPOCH 0 - PROGRESS: at 63.49% examples, 175328 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:07:26: EPOCH 0 - PROGRESS: at 66.95% examples, 177221 words/s, in_qsize 9, out_qsize 1\n",
            "INFO - 15:07:27: EPOCH 0 - PROGRESS: at 69.81% examples, 177456 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:28: EPOCH 0 - PROGRESS: at 73.35% examples, 179209 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:07:29: EPOCH 0 - PROGRESS: at 76.94% examples, 181194 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:07:30: EPOCH 0 - PROGRESS: at 80.59% examples, 182993 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:07:31: EPOCH 0 - PROGRESS: at 84.55% examples, 185410 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:07:32: EPOCH 0 - PROGRESS: at 88.27% examples, 187900 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:07:33: EPOCH 0 - PROGRESS: at 92.22% examples, 190398 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:07:34: EPOCH 0 - PROGRESS: at 95.98% examples, 192442 words/s, in_qsize 13, out_qsize 4\n",
            "INFO - 15:07:35: EPOCH 0: training on 29868966 raw words (6610317 effective words) took 33.8s, 195523 effective words/s\n",
            "INFO - 15:07:36: EPOCH 1 - PROGRESS: at 2.32% examples, 152450 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:07:37: EPOCH 1 - PROGRESS: at 4.96% examples, 163571 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:38: EPOCH 1 - PROGRESS: at 8.33% examples, 181802 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:07:39: EPOCH 1 - PROGRESS: at 12.53% examples, 202903 words/s, in_qsize 9, out_qsize 1\n",
            "INFO - 15:07:40: EPOCH 1 - PROGRESS: at 16.41% examples, 210514 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:07:41: EPOCH 1 - PROGRESS: at 20.29% examples, 216314 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:42: EPOCH 1 - PROGRESS: at 24.64% examples, 222969 words/s, in_qsize 9, out_qsize 0\n",
            "INFO - 15:07:43: EPOCH 1 - PROGRESS: at 28.40% examples, 226748 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:07:44: EPOCH 1 - PROGRESS: at 32.51% examples, 231570 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:07:45: EPOCH 1 - PROGRESS: at 36.63% examples, 234000 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:07:46: EPOCH 1 - PROGRESS: at 40.80% examples, 238016 words/s, in_qsize 10, out_qsize 2\n",
            "INFO - 15:07:48: EPOCH 1 - PROGRESS: at 44.98% examples, 240355 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:07:49: EPOCH 1 - PROGRESS: at 49.37% examples, 244087 words/s, in_qsize 7, out_qsize 3\n",
            "INFO - 15:07:50: EPOCH 1 - PROGRESS: at 53.45% examples, 245817 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:51: EPOCH 1 - PROGRESS: at 57.96% examples, 248455 words/s, in_qsize 10, out_qsize 0\n",
            "INFO - 15:07:52: EPOCH 1 - PROGRESS: at 62.08% examples, 250120 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:53: EPOCH 1 - PROGRESS: at 66.48% examples, 251934 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:07:54: EPOCH 1 - PROGRESS: at 70.69% examples, 252881 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:55: EPOCH 1 - PROGRESS: at 75.08% examples, 254680 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:07:56: EPOCH 1 - PROGRESS: at 79.14% examples, 255586 words/s, in_qsize 9, out_qsize 4\n",
            "INFO - 15:07:57: EPOCH 1 - PROGRESS: at 83.50% examples, 256904 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:07:58: EPOCH 1 - PROGRESS: at 87.47% examples, 257669 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:07:59: EPOCH 1 - PROGRESS: at 92.01% examples, 259521 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:08:04: EPOCH 1 - PROGRESS: at 93.03% examples, 212587 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:08:05: EPOCH 1 - PROGRESS: at 96.98% examples, 214574 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:08:06: EPOCH 1: training on 29868966 raw words (6610986 effective words) took 30.4s, 217200 effective words/s\n",
            "INFO - 15:08:07: EPOCH 2 - PROGRESS: at 3.39% examples, 225896 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:08:08: EPOCH 2 - PROGRESS: at 7.66% examples, 257185 words/s, in_qsize 7, out_qsize 3\n",
            "INFO - 15:08:09: EPOCH 2 - PROGRESS: at 12.32% examples, 269897 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:08:10: EPOCH 2 - PROGRESS: at 16.97% examples, 275869 words/s, in_qsize 10, out_qsize 3\n",
            "INFO - 15:08:11: EPOCH 2 - PROGRESS: at 21.72% examples, 278617 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:08:12: EPOCH 2 - PROGRESS: at 26.45% examples, 282005 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:08:13: EPOCH 2 - PROGRESS: at 30.77% examples, 284222 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:08:14: EPOCH 2 - PROGRESS: at 35.58% examples, 285934 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:08:15: EPOCH 2 - PROGRESS: at 40.25% examples, 287573 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:08:16: EPOCH 2 - PROGRESS: at 44.82% examples, 289461 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:08:17: EPOCH 2 - PROGRESS: at 49.30% examples, 289584 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:08:18: EPOCH 2 - PROGRESS: at 53.97% examples, 290105 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:08:19: EPOCH 2 - PROGRESS: at 58.62% examples, 290648 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:08:20: EPOCH 2 - PROGRESS: at 63.31% examples, 291845 words/s, in_qsize 10, out_qsize 0\n",
            "INFO - 15:08:21: EPOCH 2 - PROGRESS: at 67.66% examples, 291102 words/s, in_qsize 12, out_qsize 5\n",
            "INFO - 15:08:22: EPOCH 2 - PROGRESS: at 72.32% examples, 291949 words/s, in_qsize 10, out_qsize 1\n",
            "INFO - 15:08:23: EPOCH 2 - PROGRESS: at 76.77% examples, 291937 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:08:24: EPOCH 2 - PROGRESS: at 81.34% examples, 292282 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:08:25: EPOCH 2 - PROGRESS: at 85.47% examples, 291851 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:08:26: EPOCH 2 - PROGRESS: at 90.04% examples, 292776 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:08:27: EPOCH 2 - PROGRESS: at 94.24% examples, 292476 words/s, in_qsize 11, out_qsize 5\n",
            "INFO - 15:08:28: EPOCH 2 - PROGRESS: at 98.78% examples, 293645 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:08:28: EPOCH 2: training on 29868966 raw words (6613049 effective words) took 22.4s, 294941 effective words/s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:08:29: EPOCH 3 - PROGRESS: at 3.62% examples, 237890 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:08:30: EPOCH 3 - PROGRESS: at 7.68% examples, 254048 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:08:31: EPOCH 3 - PROGRESS: at 12.26% examples, 266095 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:08:32: EPOCH 3 - PROGRESS: at 16.97% examples, 273948 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:08:33: EPOCH 3 - PROGRESS: at 21.73% examples, 278665 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:08:34: EPOCH 3 - PROGRESS: at 26.46% examples, 280208 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:08:35: EPOCH 3 - PROGRESS: at 30.73% examples, 282470 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:08:36: EPOCH 3 - PROGRESS: at 35.43% examples, 283553 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:08:37: EPOCH 3 - PROGRESS: at 40.00% examples, 283808 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:08:38: EPOCH 3 - PROGRESS: at 44.45% examples, 285041 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:08:39: EPOCH 3 - PROGRESS: at 48.91% examples, 285891 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:08:40: EPOCH 3 - PROGRESS: at 53.56% examples, 286504 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:08:41: EPOCH 3 - PROGRESS: at 58.27% examples, 287094 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:08:42: EPOCH 3 - PROGRESS: at 62.86% examples, 288398 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:08:43: EPOCH 3 - PROGRESS: at 67.37% examples, 288036 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:08:44: EPOCH 3 - PROGRESS: at 72.09% examples, 289247 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:08:45: EPOCH 3 - PROGRESS: at 76.55% examples, 289222 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:08:47: EPOCH 3 - PROGRESS: at 80.99% examples, 289447 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:08:48: EPOCH 3 - PROGRESS: at 85.44% examples, 290087 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:08:49: EPOCH 3 - PROGRESS: at 89.76% examples, 290423 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:08:50: EPOCH 3 - PROGRESS: at 93.94% examples, 290204 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:08:51: EPOCH 3 - PROGRESS: at 98.24% examples, 290412 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:08:51: EPOCH 3: training on 29868966 raw words (6610467 effective words) took 22.6s, 292077 effective words/s\n",
            "INFO - 15:08:52: EPOCH 4 - PROGRESS: at 2.97% examples, 193354 words/s, in_qsize 10, out_qsize 6\n",
            "INFO - 15:08:53: EPOCH 4 - PROGRESS: at 7.05% examples, 228811 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:08:54: EPOCH 4 - PROGRESS: at 11.74% examples, 250123 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:08:55: EPOCH 4 - PROGRESS: at 16.16% examples, 258097 words/s, in_qsize 6, out_qsize 2\n",
            "INFO - 15:08:56: EPOCH 4 - PROGRESS: at 20.57% examples, 261432 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:08:57: EPOCH 4 - PROGRESS: at 25.22% examples, 264484 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:08:58: EPOCH 4 - PROGRESS: at 29.57% examples, 268593 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:08:59: EPOCH 4 - PROGRESS: at 34.28% examples, 270892 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:09:00: EPOCH 4 - PROGRESS: at 39.00% examples, 274189 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:09:01: EPOCH 4 - PROGRESS: at 43.33% examples, 276172 words/s, in_qsize 6, out_qsize 4\n",
            "INFO - 15:09:02: EPOCH 4 - PROGRESS: at 47.78% examples, 276930 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:09:03: EPOCH 4 - PROGRESS: at 52.42% examples, 279072 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:04: EPOCH 4 - PROGRESS: at 56.96% examples, 279211 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:09:05: EPOCH 4 - PROGRESS: at 61.57% examples, 280469 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:09:06: EPOCH 4 - PROGRESS: at 66.14% examples, 281578 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:09:07: EPOCH 4 - PROGRESS: at 70.56% examples, 282074 words/s, in_qsize 9, out_qsize 2\n",
            "INFO - 15:09:08: EPOCH 4 - PROGRESS: at 74.94% examples, 282247 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:09:09: EPOCH 4 - PROGRESS: at 79.46% examples, 282915 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:10: EPOCH 4 - PROGRESS: at 83.90% examples, 283186 words/s, in_qsize 12, out_qsize 5\n",
            "INFO - 15:09:11: EPOCH 4 - PROGRESS: at 88.44% examples, 283995 words/s, in_qsize 9, out_qsize 8\n",
            "INFO - 15:09:12: EPOCH 4 - PROGRESS: at 92.92% examples, 285107 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:09:13: EPOCH 4 - PROGRESS: at 97.45% examples, 286438 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:09:14: EPOCH 4: training on 29868966 raw words (6612124 effective words) took 23.0s, 288022 effective words/s\n",
            "INFO - 15:09:15: EPOCH 5 - PROGRESS: at 3.59% examples, 236724 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:16: EPOCH 5 - PROGRESS: at 7.66% examples, 255232 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:17: EPOCH 5 - PROGRESS: at 12.23% examples, 266708 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:09:18: EPOCH 5 - PROGRESS: at 16.94% examples, 272567 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:09:19: EPOCH 5 - PROGRESS: at 21.70% examples, 274678 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:09:20: EPOCH 5 - PROGRESS: at 26.46% examples, 276889 words/s, in_qsize 11, out_qsize 5\n",
            "INFO - 15:09:21: EPOCH 5 - PROGRESS: at 30.74% examples, 279172 words/s, in_qsize 14, out_qsize 2\n",
            "INFO - 15:09:22: EPOCH 5 - PROGRESS: at 35.32% examples, 279866 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:09:23: EPOCH 5 - PROGRESS: at 39.84% examples, 281089 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:09:24: EPOCH 5 - PROGRESS: at 44.39% examples, 282040 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:09:25: EPOCH 5 - PROGRESS: at 48.75% examples, 282569 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:09:26: EPOCH 5 - PROGRESS: at 53.34% examples, 284084 words/s, in_qsize 5, out_qsize 1\n",
            "INFO - 15:09:27: EPOCH 5 - PROGRESS: at 57.64% examples, 283068 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:09:28: EPOCH 5 - PROGRESS: at 62.15% examples, 284224 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:09:29: EPOCH 5 - PROGRESS: at 66.73% examples, 284244 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:09:30: EPOCH 5 - PROGRESS: at 71.29% examples, 285172 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:09:31: EPOCH 5 - PROGRESS: at 75.82% examples, 284684 words/s, in_qsize 9, out_qsize 6\n",
            "INFO - 15:09:32: EPOCH 5 - PROGRESS: at 80.47% examples, 285595 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:09:33: EPOCH 5 - PROGRESS: at 84.80% examples, 285561 words/s, in_qsize 9, out_qsize 1\n",
            "INFO - 15:09:34: EPOCH 5 - PROGRESS: at 88.87% examples, 285495 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:09:35: EPOCH 5 - PROGRESS: at 93.02% examples, 285512 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:09:36: EPOCH 5 - PROGRESS: at 97.35% examples, 285851 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:37: EPOCH 5: training on 29868966 raw words (6613076 effective words) took 23.1s, 286656 effective words/s\n",
            "INFO - 15:09:38: EPOCH 6 - PROGRESS: at 3.54% examples, 234651 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:09:39: EPOCH 6 - PROGRESS: at 7.73% examples, 257525 words/s, in_qsize 8, out_qsize 2\n",
            "INFO - 15:09:40: EPOCH 6 - PROGRESS: at 12.14% examples, 264646 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:09:41: EPOCH 6 - PROGRESS: at 16.80% examples, 272318 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:09:42: EPOCH 6 - PROGRESS: at 21.43% examples, 276217 words/s, in_qsize 8, out_qsize 4\n",
            "INFO - 15:09:43: EPOCH 6 - PROGRESS: at 26.29% examples, 278982 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:09:44: EPOCH 6 - PROGRESS: at 30.63% examples, 281605 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:09:45: EPOCH 6 - PROGRESS: at 35.37% examples, 282848 words/s, in_qsize 10, out_qsize 3\n",
            "INFO - 15:09:46: EPOCH 6 - PROGRESS: at 40.00% examples, 283720 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:09:47: EPOCH 6 - PROGRESS: at 44.46% examples, 284010 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:09:48: EPOCH 6 - PROGRESS: at 49.00% examples, 284624 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:09:49: EPOCH 6 - PROGRESS: at 53.73% examples, 286249 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:09:50: EPOCH 6 - PROGRESS: at 58.20% examples, 285873 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:51: EPOCH 6 - PROGRESS: at 62.65% examples, 286135 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:09:52: EPOCH 6 - PROGRESS: at 67.13% examples, 285969 words/s, in_qsize 10, out_qsize 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:09:53: EPOCH 6 - PROGRESS: at 71.66% examples, 286794 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:54: EPOCH 6 - PROGRESS: at 76.37% examples, 287126 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:09:55: EPOCH 6 - PROGRESS: at 80.93% examples, 287817 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:09:56: EPOCH 6 - PROGRESS: at 85.35% examples, 287768 words/s, in_qsize 13, out_qsize 3\n",
            "INFO - 15:09:57: EPOCH 6 - PROGRESS: at 89.96% examples, 288403 words/s, in_qsize 13, out_qsize 3\n",
            "INFO - 15:09:58: EPOCH 6 - PROGRESS: at 94.51% examples, 289258 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:09:59: EPOCH 6 - PROGRESS: at 98.88% examples, 290035 words/s, in_qsize 14, out_qsize 2\n",
            "INFO - 15:10:00: EPOCH 6: training on 29868966 raw words (6608201 effective words) took 22.7s, 291517 effective words/s\n",
            "INFO - 15:10:01: EPOCH 7 - PROGRESS: at 3.62% examples, 238995 words/s, in_qsize 11, out_qsize 5\n",
            "INFO - 15:10:02: EPOCH 7 - PROGRESS: at 7.83% examples, 256010 words/s, in_qsize 11, out_qsize 5\n",
            "INFO - 15:10:03: EPOCH 7 - PROGRESS: at 12.46% examples, 268165 words/s, in_qsize 9, out_qsize 6\n",
            "INFO - 15:10:04: EPOCH 7 - PROGRESS: at 17.04% examples, 272271 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:10:05: EPOCH 7 - PROGRESS: at 21.70% examples, 275793 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:10:06: EPOCH 7 - PROGRESS: at 26.44% examples, 279383 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:10:07: EPOCH 7 - PROGRESS: at 29.91% examples, 272687 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:10:08: EPOCH 7 - PROGRESS: at 34.30% examples, 273231 words/s, in_qsize 9, out_qsize 4\n",
            "INFO - 15:10:09: EPOCH 7 - PROGRESS: at 38.90% examples, 275498 words/s, in_qsize 10, out_qsize 1\n",
            "INFO - 15:10:10: EPOCH 7 - PROGRESS: at 43.23% examples, 276724 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:11: EPOCH 7 - PROGRESS: at 47.74% examples, 278253 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:10:12: EPOCH 7 - PROGRESS: at 52.02% examples, 278587 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:13: EPOCH 7 - PROGRESS: at 56.74% examples, 279910 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:10:14: EPOCH 7 - PROGRESS: at 61.33% examples, 280947 words/s, in_qsize 10, out_qsize 5\n",
            "INFO - 15:10:15: EPOCH 7 - PROGRESS: at 65.72% examples, 281653 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:10:16: EPOCH 7 - PROGRESS: at 70.40% examples, 282532 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:10:17: EPOCH 7 - PROGRESS: at 75.11% examples, 283967 words/s, in_qsize 12, out_qsize 0\n",
            "INFO - 15:10:18: EPOCH 7 - PROGRESS: at 79.46% examples, 284083 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:19: EPOCH 7 - PROGRESS: at 83.96% examples, 284695 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:20: EPOCH 7 - PROGRESS: at 88.37% examples, 285418 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:21: EPOCH 7 - PROGRESS: at 92.96% examples, 286727 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:10:22: EPOCH 7 - PROGRESS: at 97.01% examples, 286509 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:23: EPOCH 7: training on 29868966 raw words (6609075 effective words) took 23.0s, 287612 effective words/s\n",
            "INFO - 15:10:24: EPOCH 8 - PROGRESS: at 3.30% examples, 220173 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:10:25: EPOCH 8 - PROGRESS: at 7.30% examples, 242612 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:26: EPOCH 8 - PROGRESS: at 11.81% examples, 255440 words/s, in_qsize 5, out_qsize 9\n",
            "INFO - 15:10:27: EPOCH 8 - PROGRESS: at 16.30% examples, 262196 words/s, in_qsize 13, out_qsize 6\n",
            "INFO - 15:10:28: EPOCH 8 - PROGRESS: at 20.85% examples, 266803 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:10:29: EPOCH 8 - PROGRESS: at 25.48% examples, 268710 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:10:30: EPOCH 8 - PROGRESS: at 29.71% examples, 270956 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:10:31: EPOCH 8 - PROGRESS: at 34.46% examples, 274870 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:32: EPOCH 8 - PROGRESS: at 38.96% examples, 276018 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:33: EPOCH 8 - PROGRESS: at 43.47% examples, 278926 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:10:34: EPOCH 8 - PROGRESS: at 47.81% examples, 279026 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:35: EPOCH 8 - PROGRESS: at 52.20% examples, 280013 words/s, in_qsize 9, out_qsize 4\n",
            "INFO - 15:10:36: EPOCH 8 - PROGRESS: at 56.74% examples, 280160 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:37: EPOCH 8 - PROGRESS: at 61.39% examples, 281583 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:38: EPOCH 8 - PROGRESS: at 65.77% examples, 281738 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:10:39: EPOCH 8 - PROGRESS: at 69.59% examples, 279824 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:40: EPOCH 8 - PROGRESS: at 74.09% examples, 280185 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:10:41: EPOCH 8 - PROGRESS: at 78.49% examples, 281150 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:42: EPOCH 8 - PROGRESS: at 82.82% examples, 281266 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:10:43: EPOCH 8 - PROGRESS: at 87.22% examples, 282229 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:10:44: EPOCH 8 - PROGRESS: at 91.72% examples, 283278 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:10:45: EPOCH 8 - PROGRESS: at 96.06% examples, 283720 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:10:46: EPOCH 8: training on 29868966 raw words (6611291 effective words) took 23.1s, 286062 effective words/s\n",
            "INFO - 15:10:47: EPOCH 9 - PROGRESS: at 3.71% examples, 242202 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:48: EPOCH 9 - PROGRESS: at 7.86% examples, 256533 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:10:49: EPOCH 9 - PROGRESS: at 12.50% examples, 269247 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:10:50: EPOCH 9 - PROGRESS: at 17.17% examples, 275148 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:51: EPOCH 9 - PROGRESS: at 21.96% examples, 277240 words/s, in_qsize 14, out_qsize 1\n",
            "INFO - 15:10:52: EPOCH 9 - PROGRESS: at 26.68% examples, 281560 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:10:53: EPOCH 9 - PROGRESS: at 30.96% examples, 283461 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:10:54: EPOCH 9 - PROGRESS: at 35.54% examples, 283119 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:10:55: EPOCH 9 - PROGRESS: at 40.23% examples, 285192 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:10:56: EPOCH 9 - PROGRESS: at 44.52% examples, 285399 words/s, in_qsize 14, out_qsize 1\n",
            "INFO - 15:10:57: EPOCH 9 - PROGRESS: at 48.79% examples, 285075 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:10:58: EPOCH 9 - PROGRESS: at 53.09% examples, 284286 words/s, in_qsize 14, out_qsize 5\n",
            "INFO - 15:10:59: EPOCH 9 - PROGRESS: at 57.83% examples, 284537 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:00: EPOCH 9 - PROGRESS: at 62.28% examples, 285282 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:01: EPOCH 9 - PROGRESS: at 66.66% examples, 284949 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:11:02: EPOCH 9 - PROGRESS: at 71.26% examples, 285901 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:11:03: EPOCH 9 - PROGRESS: at 75.60% examples, 285588 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:11:04: EPOCH 9 - PROGRESS: at 80.06% examples, 285894 words/s, in_qsize 9, out_qsize 6\n",
            "INFO - 15:11:05: EPOCH 9 - PROGRESS: at 84.68% examples, 286424 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:11:06: EPOCH 9 - PROGRESS: at 89.13% examples, 287234 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:07: EPOCH 9 - PROGRESS: at 93.59% examples, 287996 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:11:08: EPOCH 9 - PROGRESS: at 97.88% examples, 288396 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:11:08: EPOCH 9: training on 29868966 raw words (6610430 effective words) took 22.8s, 289979 effective words/s\n",
            "INFO - 15:11:13: EPOCH 10 - PROGRESS: at 2.34% examples, 33749 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:11:14: EPOCH 10 - PROGRESS: at 5.38% examples, 63355 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:11:15: EPOCH 10 - PROGRESS: at 9.47% examples, 94607 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:11:16: EPOCH 10 - PROGRESS: at 14.29% examples, 120807 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:11:17: EPOCH 10 - PROGRESS: at 18.95% examples, 141357 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:11:18: EPOCH 10 - PROGRESS: at 23.50% examples, 155757 words/s, in_qsize 14, out_qsize 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:11:19: EPOCH 10 - PROGRESS: at 27.98% examples, 168766 words/s, in_qsize 10, out_qsize 7\n",
            "INFO - 15:11:20: EPOCH 10 - PROGRESS: at 32.77% examples, 180928 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:21: EPOCH 10 - PROGRESS: at 37.02% examples, 188294 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:11:22: EPOCH 10 - PROGRESS: at 41.49% examples, 196100 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:23: EPOCH 10 - PROGRESS: at 45.87% examples, 202285 words/s, in_qsize 10, out_qsize 2\n",
            "INFO - 15:11:24: EPOCH 10 - PROGRESS: at 50.22% examples, 207414 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:11:25: EPOCH 10 - PROGRESS: at 54.56% examples, 211867 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:26: EPOCH 10 - PROGRESS: at 59.11% examples, 215984 words/s, in_qsize 12, out_qsize 6\n",
            "INFO - 15:11:27: EPOCH 10 - PROGRESS: at 63.56% examples, 219920 words/s, in_qsize 10, out_qsize 6\n",
            "INFO - 15:11:28: EPOCH 10 - PROGRESS: at 68.01% examples, 223305 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:11:29: EPOCH 10 - PROGRESS: at 72.62% examples, 226219 words/s, in_qsize 9, out_qsize 6\n",
            "INFO - 15:11:30: EPOCH 10 - PROGRESS: at 76.93% examples, 229009 words/s, in_qsize 10, out_qsize 9\n",
            "INFO - 15:11:31: EPOCH 10 - PROGRESS: at 81.53% examples, 232005 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:11:32: EPOCH 10 - PROGRESS: at 85.75% examples, 234514 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:11:33: EPOCH 10 - PROGRESS: at 90.18% examples, 237083 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:11:35: EPOCH 10 - PROGRESS: at 93.30% examples, 235871 words/s, in_qsize 9, out_qsize 7\n",
            "INFO - 15:11:36: EPOCH 10 - PROGRESS: at 96.21% examples, 234314 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:37: EPOCH 10 - PROGRESS: at 98.88% examples, 232155 words/s, in_qsize 10, out_qsize 5\n",
            "INFO - 15:11:37: EPOCH 10: training on 29868966 raw words (6608963 effective words) took 28.5s, 231581 effective words/s\n",
            "INFO - 15:11:38: EPOCH 11 - PROGRESS: at 1.16% examples, 72192 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:39: EPOCH 11 - PROGRESS: at 3.07% examples, 99976 words/s, in_qsize 9, out_qsize 0\n",
            "INFO - 15:11:40: EPOCH 11 - PROGRESS: at 4.41% examples, 96149 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:11:41: EPOCH 11 - PROGRESS: at 7.02% examples, 114846 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:13:41: EPOCH 11 - PROGRESS: at 8.69% examples, 112856 words/s, in_qsize 10, out_qsize 3\n",
            "INFO - 15:13:42: EPOCH 11 - PROGRESS: at 9.15% examples, 97965 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:13:43: EPOCH 11 - PROGRESS: at 10.87% examples, 97861 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:13:44: EPOCH 11 - PROGRESS: at 14.17% examples, 111329 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:13:45: EPOCH 11 - PROGRESS: at 18.11% examples, 126786 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:13:46: EPOCH 11 - PROGRESS: at 22.14% examples, 139250 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:13:47: EPOCH 11 - PROGRESS: at 26.23% examples, 149544 words/s, in_qsize 10, out_qsize 2\n",
            "INFO - 15:13:48: EPOCH 11 - PROGRESS: at 29.38% examples, 154924 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:13:49: EPOCH 11 - PROGRESS: at 33.07% examples, 161245 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:13:50: EPOCH 11 - PROGRESS: at 35.77% examples, 162120 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:13:51: EPOCH 11 - PROGRESS: at 39.27% examples, 165861 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:13:52: EPOCH 11 - PROGRESS: at 43.02% examples, 171161 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:13:53: EPOCH 11 - PROGRESS: at 47.05% examples, 176516 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:13:54: EPOCH 11 - PROGRESS: at 51.31% examples, 182010 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:13:55: EPOCH 11 - PROGRESS: at 55.46% examples, 186525 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:13:56: EPOCH 11 - PROGRESS: at 59.63% examples, 190149 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:13:57: EPOCH 11 - PROGRESS: at 63.80% examples, 193970 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:13:58: EPOCH 11 - PROGRESS: at 68.01% examples, 197574 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:13:59: EPOCH 11 - PROGRESS: at 72.25% examples, 200837 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:00: EPOCH 11 - PROGRESS: at 76.42% examples, 203800 words/s, in_qsize 10, out_qsize 5\n",
            "INFO - 15:14:01: EPOCH 11 - PROGRESS: at 80.80% examples, 207175 words/s, in_qsize 12, out_qsize 0\n",
            "INFO - 15:14:02: EPOCH 11 - PROGRESS: at 84.91% examples, 209748 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:14:03: EPOCH 11 - PROGRESS: at 89.04% examples, 212451 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:04: EPOCH 11 - PROGRESS: at 93.09% examples, 214646 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:14:05: EPOCH 11 - PROGRESS: at 97.18% examples, 216911 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:14:06: EPOCH 11: training on 29868966 raw words (6615483 effective words) took 30.2s, 219338 effective words/s\n",
            "INFO - 15:14:07: EPOCH 12 - PROGRESS: at 2.69% examples, 176204 words/s, in_qsize 8, out_qsize 0\n",
            "INFO - 15:14:08: EPOCH 12 - PROGRESS: at 5.51% examples, 177536 words/s, in_qsize 10, out_qsize 5\n",
            "INFO - 15:14:09: EPOCH 12 - PROGRESS: at 8.66% examples, 188814 words/s, in_qsize 9, out_qsize 4\n",
            "INFO - 15:14:10: EPOCH 12 - PROGRESS: at 12.70% examples, 205015 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:14:11: EPOCH 12 - PROGRESS: at 17.05% examples, 218125 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:14:12: EPOCH 12 - PROGRESS: at 21.26% examples, 226015 words/s, in_qsize 10, out_qsize 5\n",
            "INFO - 15:14:13: EPOCH 12 - PROGRESS: at 25.75% examples, 233056 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:14: EPOCH 12 - PROGRESS: at 29.65% examples, 237298 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:14:15: EPOCH 12 - PROGRESS: at 34.30% examples, 243455 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:14:16: EPOCH 12 - PROGRESS: at 38.52% examples, 246527 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:14:17: EPOCH 12 - PROGRESS: at 41.84% examples, 244596 words/s, in_qsize 12, out_qsize 0\n",
            "INFO - 15:14:18: EPOCH 12 - PROGRESS: at 45.28% examples, 240989 words/s, in_qsize 11, out_qsize 8\n",
            "INFO - 15:14:19: EPOCH 12 - PROGRESS: at 49.26% examples, 242281 words/s, in_qsize 11, out_qsize 5\n",
            "INFO - 15:14:20: EPOCH 12 - PROGRESS: at 53.43% examples, 244364 words/s, in_qsize 9, out_qsize 6\n",
            "INFO - 15:14:21: EPOCH 12 - PROGRESS: at 57.59% examples, 245464 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:14:22: EPOCH 12 - PROGRESS: at 62.06% examples, 247545 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:23: EPOCH 12 - PROGRESS: at 66.35% examples, 248624 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:24: EPOCH 12 - PROGRESS: at 70.47% examples, 249753 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:25: EPOCH 12 - PROGRESS: at 74.60% examples, 250806 words/s, in_qsize 10, out_qsize 2\n",
            "INFO - 15:14:26: EPOCH 12 - PROGRESS: at 78.65% examples, 251932 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:27: EPOCH 12 - PROGRESS: at 82.82% examples, 252765 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:28: EPOCH 12 - PROGRESS: at 87.15% examples, 254670 words/s, in_qsize 10, out_qsize 1\n",
            "INFO - 15:14:29: EPOCH 12 - PROGRESS: at 91.36% examples, 255916 words/s, in_qsize 9, out_qsize 2\n",
            "INFO - 15:14:30: EPOCH 12 - PROGRESS: at 95.55% examples, 257094 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:14:31: EPOCH 12: training on 29868966 raw words (6609177 effective words) took 25.4s, 259813 effective words/s\n",
            "INFO - 15:14:32: EPOCH 13 - PROGRESS: at 3.04% examples, 201197 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:14:33: EPOCH 13 - PROGRESS: at 6.68% examples, 220880 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:14:34: EPOCH 13 - PROGRESS: at 11.10% examples, 240904 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:14:35: EPOCH 13 - PROGRESS: at 15.62% examples, 253406 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:14:36: EPOCH 13 - PROGRESS: at 19.95% examples, 257094 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:14:37: EPOCH 13 - PROGRESS: at 23.62% examples, 250220 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:38: EPOCH 13 - PROGRESS: at 27.52% examples, 252034 words/s, in_qsize 10, out_qsize 2\n",
            "INFO - 15:14:39: EPOCH 13 - PROGRESS: at 31.48% examples, 253428 words/s, in_qsize 8, out_qsize 2\n",
            "INFO - 15:14:40: EPOCH 13 - PROGRESS: at 34.96% examples, 249391 words/s, in_qsize 13, out_qsize 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:14:41: EPOCH 13 - PROGRESS: at 38.43% examples, 246844 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:14:42: EPOCH 13 - PROGRESS: at 41.78% examples, 244935 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:43: EPOCH 13 - PROGRESS: at 45.18% examples, 243041 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:44: EPOCH 13 - PROGRESS: at 49.23% examples, 244410 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:14:45: EPOCH 13 - PROGRESS: at 53.49% examples, 246170 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:14:46: EPOCH 13 - PROGRESS: at 57.77% examples, 247373 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:14:48: EPOCH 13 - PROGRESS: at 61.84% examples, 248335 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:14:49: EPOCH 13 - PROGRESS: at 65.89% examples, 249105 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:50: EPOCH 13 - PROGRESS: at 69.92% examples, 249511 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:14:51: EPOCH 13 - PROGRESS: at 74.05% examples, 250453 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:14:52: EPOCH 13 - PROGRESS: at 78.19% examples, 251907 words/s, in_qsize 8, out_qsize 0\n",
            "INFO - 15:14:53: EPOCH 13 - PROGRESS: at 82.20% examples, 251721 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:14:54: EPOCH 13 - PROGRESS: at 86.39% examples, 253333 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:14:55: EPOCH 13 - PROGRESS: at 90.43% examples, 253917 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:14:56: EPOCH 13 - PROGRESS: at 94.31% examples, 254507 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:14:57: EPOCH 13 - PROGRESS: at 98.11% examples, 254970 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:14:57: EPOCH 13: training on 29868966 raw words (6612163 effective words) took 25.8s, 256421 effective words/s\n",
            "INFO - 15:14:58: EPOCH 14 - PROGRESS: at 3.31% examples, 210990 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:14:59: EPOCH 14 - PROGRESS: at 6.75% examples, 219362 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:15:00: EPOCH 14 - PROGRESS: at 11.07% examples, 237492 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:15:01: EPOCH 14 - PROGRESS: at 15.40% examples, 246990 words/s, in_qsize 14, out_qsize 1\n",
            "INFO - 15:15:02: EPOCH 14 - PROGRESS: at 19.92% examples, 253354 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:03: EPOCH 14 - PROGRESS: at 24.46% examples, 257709 words/s, in_qsize 9, out_qsize 4\n",
            "INFO - 15:15:04: EPOCH 14 - PROGRESS: at 28.72% examples, 260414 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:15:05: EPOCH 14 - PROGRESS: at 33.24% examples, 263750 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:15:06: EPOCH 14 - PROGRESS: at 37.68% examples, 264802 words/s, in_qsize 13, out_qsize 2\n",
            "INFO - 15:15:07: EPOCH 14 - PROGRESS: at 41.82% examples, 266363 words/s, in_qsize 5, out_qsize 7\n",
            "INFO - 15:15:08: EPOCH 14 - PROGRESS: at 46.04% examples, 267302 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:15:09: EPOCH 14 - PROGRESS: at 50.50% examples, 269126 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:10: EPOCH 14 - PROGRESS: at 54.67% examples, 269528 words/s, in_qsize 9, out_qsize 3\n",
            "INFO - 15:15:11: EPOCH 14 - PROGRESS: at 58.97% examples, 269228 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:15:12: EPOCH 14 - PROGRESS: at 63.03% examples, 269158 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:15:13: EPOCH 14 - PROGRESS: at 67.25% examples, 269237 words/s, in_qsize 10, out_qsize 6\n",
            "INFO - 15:15:14: EPOCH 14 - PROGRESS: at 71.43% examples, 269546 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:15:15: EPOCH 14 - PROGRESS: at 75.50% examples, 269353 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:15:16: EPOCH 14 - PROGRESS: at 79.35% examples, 268387 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:17: EPOCH 14 - PROGRESS: at 82.93% examples, 266826 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:15:18: EPOCH 14 - PROGRESS: at 86.56% examples, 265995 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:15:19: EPOCH 14 - PROGRESS: at 90.17% examples, 265068 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:15:20: EPOCH 14 - PROGRESS: at 94.00% examples, 265094 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:15:21: EPOCH 14 - PROGRESS: at 97.94% examples, 265442 words/s, in_qsize 9, out_qsize 4\n",
            "INFO - 15:15:22: EPOCH 14: training on 29868966 raw words (6612651 effective words) took 24.7s, 267179 effective words/s\n",
            "INFO - 15:15:23: EPOCH 15 - PROGRESS: at 3.21% examples, 202244 words/s, in_qsize 12, out_qsize 5\n",
            "INFO - 15:15:24: EPOCH 15 - PROGRESS: at 7.02% examples, 226794 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:15:25: EPOCH 15 - PROGRESS: at 11.51% examples, 242799 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:26: EPOCH 15 - PROGRESS: at 15.59% examples, 248532 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:15:27: EPOCH 15 - PROGRESS: at 19.73% examples, 251812 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:15:28: EPOCH 15 - PROGRESS: at 24.18% examples, 254896 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:15:29: EPOCH 15 - PROGRESS: at 28.57% examples, 258443 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:30: EPOCH 15 - PROGRESS: at 32.97% examples, 261139 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:31: EPOCH 15 - PROGRESS: at 37.50% examples, 263815 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:15:32: EPOCH 15 - PROGRESS: at 41.59% examples, 264934 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:15:33: EPOCH 15 - PROGRESS: at 45.95% examples, 265614 words/s, in_qsize 11, out_qsize 3\n",
            "INFO - 15:15:34: EPOCH 15 - PROGRESS: at 50.25% examples, 266623 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:15:35: EPOCH 15 - PROGRESS: at 54.48% examples, 267335 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:36: EPOCH 15 - PROGRESS: at 58.78% examples, 267725 words/s, in_qsize 11, out_qsize 6\n",
            "INFO - 15:15:37: EPOCH 15 - PROGRESS: at 63.24% examples, 269220 words/s, in_qsize 6, out_qsize 7\n",
            "INFO - 15:15:38: EPOCH 15 - PROGRESS: at 67.50% examples, 269016 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:15:39: EPOCH 15 - PROGRESS: at 71.85% examples, 269926 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:40: EPOCH 15 - PROGRESS: at 76.21% examples, 270693 words/s, in_qsize 9, out_qsize 2\n",
            "INFO - 15:15:41: EPOCH 15 - PROGRESS: at 80.19% examples, 270338 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:15:42: EPOCH 15 - PROGRESS: at 84.58% examples, 271183 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:43: EPOCH 15 - PROGRESS: at 88.72% examples, 272154 words/s, in_qsize 10, out_qsize 5\n",
            "INFO - 15:15:44: EPOCH 15 - PROGRESS: at 93.15% examples, 273349 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:45: EPOCH 15 - PROGRESS: at 97.61% examples, 274770 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:46: EPOCH 15: training on 29868966 raw words (6612515 effective words) took 23.9s, 276624 effective words/s\n",
            "INFO - 15:15:47: EPOCH 16 - PROGRESS: at 3.44% examples, 228021 words/s, in_qsize 10, out_qsize 6\n",
            "INFO - 15:15:48: EPOCH 16 - PROGRESS: at 7.47% examples, 249231 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:49: EPOCH 16 - PROGRESS: at 12.04% examples, 259226 words/s, in_qsize 14, out_qsize 1\n",
            "INFO - 15:15:50: EPOCH 16 - PROGRESS: at 16.34% examples, 261753 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:15:51: EPOCH 16 - PROGRESS: at 20.87% examples, 267101 words/s, in_qsize 13, out_qsize 4\n",
            "INFO - 15:15:52: EPOCH 16 - PROGRESS: at 25.65% examples, 270866 words/s, in_qsize 12, out_qsize 0\n",
            "INFO - 15:15:53: EPOCH 16 - PROGRESS: at 29.81% examples, 272282 words/s, in_qsize 14, out_qsize 1\n",
            "INFO - 15:15:54: EPOCH 16 - PROGRESS: at 34.47% examples, 274839 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:55: EPOCH 16 - PROGRESS: at 38.92% examples, 275772 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:15:56: EPOCH 16 - PROGRESS: at 43.43% examples, 278626 words/s, in_qsize 10, out_qsize 2\n",
            "INFO - 15:15:57: EPOCH 16 - PROGRESS: at 47.96% examples, 280207 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:15:58: EPOCH 16 - PROGRESS: at 52.31% examples, 280533 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:15:59: EPOCH 16 - PROGRESS: at 56.90% examples, 281101 words/s, in_qsize 11, out_qsize 5\n",
            "INFO - 15:16:00: EPOCH 16 - PROGRESS: at 61.46% examples, 281570 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:16:01: EPOCH 16 - PROGRESS: at 66.04% examples, 282706 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:16:02: EPOCH 16 - PROGRESS: at 70.35% examples, 282682 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:03: EPOCH 16 - PROGRESS: at 74.60% examples, 282170 words/s, in_qsize 14, out_qsize 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:16:04: EPOCH 16 - PROGRESS: at 78.83% examples, 282455 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:16:05: EPOCH 16 - PROGRESS: at 83.16% examples, 282094 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:16:06: EPOCH 16 - PROGRESS: at 87.50% examples, 282776 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:16:07: EPOCH 16 - PROGRESS: at 92.16% examples, 284232 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:16:08: EPOCH 16 - PROGRESS: at 96.60% examples, 285271 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:16:09: EPOCH 16: training on 29868966 raw words (6613715 effective words) took 23.1s, 286728 effective words/s\n",
            "INFO - 15:16:10: EPOCH 17 - PROGRESS: at 3.45% examples, 223501 words/s, in_qsize 13, out_qsize 4\n",
            "INFO - 15:16:11: EPOCH 17 - PROGRESS: at 7.43% examples, 245759 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:16:12: EPOCH 17 - PROGRESS: at 12.01% examples, 259173 words/s, in_qsize 8, out_qsize 8\n",
            "INFO - 15:16:13: EPOCH 17 - PROGRESS: at 16.77% examples, 267848 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:16:14: EPOCH 17 - PROGRESS: at 21.48% examples, 273660 words/s, in_qsize 12, out_qsize 0\n",
            "INFO - 15:16:15: EPOCH 17 - PROGRESS: at 26.23% examples, 275805 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:16: EPOCH 17 - PROGRESS: at 30.36% examples, 277479 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:16:17: EPOCH 17 - PROGRESS: at 35.25% examples, 279229 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:18: EPOCH 17 - PROGRESS: at 39.51% examples, 279290 words/s, in_qsize 11, out_qsize 2\n",
            "INFO - 15:16:19: EPOCH 17 - PROGRESS: at 43.77% examples, 279887 words/s, in_qsize 6, out_qsize 10\n",
            "INFO - 15:16:20: EPOCH 17 - PROGRESS: at 48.50% examples, 281512 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:16:21: EPOCH 17 - PROGRESS: at 53.06% examples, 282299 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:22: EPOCH 17 - PROGRESS: at 57.73% examples, 282904 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:23: EPOCH 17 - PROGRESS: at 62.19% examples, 283666 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:16:24: EPOCH 17 - PROGRESS: at 66.76% examples, 284393 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:16:25: EPOCH 17 - PROGRESS: at 71.21% examples, 284953 words/s, in_qsize 10, out_qsize 2\n",
            "INFO - 15:16:26: EPOCH 17 - PROGRESS: at 75.40% examples, 284509 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:16:27: EPOCH 17 - PROGRESS: at 79.73% examples, 284422 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:16:28: EPOCH 17 - PROGRESS: at 84.03% examples, 284089 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:16:29: EPOCH 17 - PROGRESS: at 88.37% examples, 285015 words/s, in_qsize 10, out_qsize 3\n",
            "INFO - 15:16:30: EPOCH 17 - PROGRESS: at 92.62% examples, 285014 words/s, in_qsize 9, out_qsize 5\n",
            "INFO - 15:16:31: EPOCH 17 - PROGRESS: at 96.81% examples, 285077 words/s, in_qsize 9, out_qsize 6\n",
            "INFO - 15:16:32: EPOCH 17: training on 29868966 raw words (6612650 effective words) took 23.0s, 286940 effective words/s\n",
            "INFO - 15:16:33: EPOCH 18 - PROGRESS: at 3.44% examples, 223835 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:34: EPOCH 18 - PROGRESS: at 7.20% examples, 238637 words/s, in_qsize 8, out_qsize 6\n",
            "INFO - 15:16:35: EPOCH 18 - PROGRESS: at 11.86% examples, 255666 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:39: EPOCH 18 - PROGRESS: at 13.44% examples, 116986 words/s, in_qsize 10, out_qsize 5\n",
            "INFO - 15:16:40: EPOCH 18 - PROGRESS: at 17.64% examples, 134518 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:16:41: EPOCH 18 - PROGRESS: at 22.00% examples, 148696 words/s, in_qsize 9, out_qsize 8\n",
            "INFO - 15:16:42: EPOCH 18 - PROGRESS: at 26.63% examples, 162705 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:43: EPOCH 18 - PROGRESS: at 30.68% examples, 172644 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:16:44: EPOCH 18 - PROGRESS: at 35.33% examples, 182007 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:45: EPOCH 18 - PROGRESS: at 39.74% examples, 189814 words/s, in_qsize 9, out_qsize 1\n",
            "INFO - 15:16:46: EPOCH 18 - PROGRESS: at 44.16% examples, 197041 words/s, in_qsize 8, out_qsize 1\n",
            "INFO - 15:16:47: EPOCH 18 - PROGRESS: at 48.49% examples, 202762 words/s, in_qsize 11, out_qsize 0\n",
            "INFO - 15:16:49: EPOCH 18 - PROGRESS: at 52.85% examples, 207322 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:16:50: EPOCH 18 - PROGRESS: at 57.36% examples, 211745 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:16:51: EPOCH 18 - PROGRESS: at 61.74% examples, 215895 words/s, in_qsize 6, out_qsize 3\n",
            "INFO - 15:16:52: EPOCH 18 - PROGRESS: at 66.00% examples, 218707 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:16:53: EPOCH 18 - PROGRESS: at 70.21% examples, 221500 words/s, in_qsize 13, out_qsize 1\n",
            "INFO - 15:16:54: EPOCH 18 - PROGRESS: at 74.66% examples, 224409 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:16:55: EPOCH 18 - PROGRESS: at 78.86% examples, 226976 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:16:56: EPOCH 18 - PROGRESS: at 83.15% examples, 228985 words/s, in_qsize 13, out_qsize 3\n",
            "INFO - 15:16:57: EPOCH 18 - PROGRESS: at 87.48% examples, 231538 words/s, in_qsize 12, out_qsize 2\n",
            "INFO - 15:16:58: EPOCH 18 - PROGRESS: at 91.88% examples, 233803 words/s, in_qsize 10, out_qsize 6\n",
            "INFO - 15:16:59: EPOCH 18 - PROGRESS: at 96.16% examples, 236162 words/s, in_qsize 10, out_qsize 3\n",
            "INFO - 15:17:00: EPOCH 18 - PROGRESS: at 99.05% examples, 234755 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:17:00: EPOCH 18: training on 29868966 raw words (6612986 effective words) took 28.1s, 235729 effective words/s\n",
            "INFO - 15:17:01: EPOCH 19 - PROGRESS: at 1.90% examples, 112613 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:17:02: EPOCH 19 - PROGRESS: at 4.57% examples, 150714 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:17:03: EPOCH 19 - PROGRESS: at 7.76% examples, 167830 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:17:04: EPOCH 19 - PROGRESS: at 11.88% examples, 188274 words/s, in_qsize 14, out_qsize 1\n",
            "INFO - 15:17:05: EPOCH 19 - PROGRESS: at 15.75% examples, 197919 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:17:06: EPOCH 19 - PROGRESS: at 19.41% examples, 203738 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:20:40: EPOCH 19 - PROGRESS: at 22.25% examples, 199903 words/s, in_qsize 9, out_qsize 3\n",
            "INFO - 15:20:41: EPOCH 19 - PROGRESS: at 25.47% examples, 200186 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:20:42: EPOCH 19 - PROGRESS: at 28.61% examples, 201863 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:20:43: EPOCH 19 - PROGRESS: at 30.50% examples, 195158 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:20:44: EPOCH 19 - PROGRESS: at 33.88% examples, 196338 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:20:45: EPOCH 19 - PROGRESS: at 37.45% examples, 198477 words/s, in_qsize 13, out_qsize 4\n",
            "INFO - 15:20:46: EPOCH 19 - PROGRESS: at 41.21% examples, 202607 words/s, in_qsize 10, out_qsize 4\n",
            "INFO - 15:20:47: EPOCH 19 - PROGRESS: at 45.42% examples, 207530 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:20:48: EPOCH 19 - PROGRESS: at 49.61% examples, 211911 words/s, in_qsize 5, out_qsize 0\n",
            "INFO - 15:20:49: EPOCH 19 - PROGRESS: at 53.49% examples, 214318 words/s, in_qsize 13, out_qsize 0\n",
            "INFO - 15:20:50: EPOCH 19 - PROGRESS: at 57.76% examples, 217460 words/s, in_qsize 12, out_qsize 4\n",
            "INFO - 15:20:51: EPOCH 19 - PROGRESS: at 62.17% examples, 221667 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 15:20:52: EPOCH 19 - PROGRESS: at 66.48% examples, 224279 words/s, in_qsize 9, out_qsize 8\n",
            "INFO - 15:20:53: EPOCH 19 - PROGRESS: at 70.95% examples, 227708 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:20:54: EPOCH 19 - PROGRESS: at 74.87% examples, 228540 words/s, in_qsize 12, out_qsize 5\n",
            "INFO - 15:20:55: EPOCH 19 - PROGRESS: at 79.04% examples, 230794 words/s, in_qsize 12, out_qsize 3\n",
            "INFO - 15:20:56: EPOCH 19 - PROGRESS: at 83.35% examples, 232999 words/s, in_qsize 12, out_qsize 1\n",
            "INFO - 15:20:57: EPOCH 19 - PROGRESS: at 87.37% examples, 234709 words/s, in_qsize 14, out_qsize 0\n",
            "INFO - 15:20:58: EPOCH 19 - PROGRESS: at 91.46% examples, 236280 words/s, in_qsize 11, out_qsize 4\n",
            "INFO - 15:20:59: EPOCH 19 - PROGRESS: at 95.65% examples, 238390 words/s, in_qsize 10, out_qsize 0\n",
            "INFO - 15:21:00: EPOCH 19 - PROGRESS: at 99.93% examples, 240662 words/s, in_qsize 2, out_qsize 1\n",
            "INFO - 15:21:00: EPOCH 19: training on 29868966 raw words (6611488 effective words) took 27.5s, 240809 effective words/s\n",
            "INFO - 15:21:00: Word2Vec lifecycle event {'msg': 'training on 597379320 raw words (132230807 effective words) took 507.4s, 260625 effective words/s', 'datetime': '2022-11-30T15:21:00.839258', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'train'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1j/vhrxwjz94tn0tsz00qlnqw8m0000gn/T/ipykernel_10709/258766345.py:7: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  w2v_model.init_sims(replace=True)\n",
            "WARNING - 15:21:00: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time to train the model: 13.98 mins\n"
          ]
        }
      ],
      "source": [
        "start = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=20, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
        "\n",
        "w2v_model.init_sims(replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSBe6DgJsPTe",
        "outputId": "7404abaa-a0d4-4cbf-c6ed-72199fbfbc7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 15:21:00: Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-11-30T15:21:00.957790', 'gensim': '4.2.0', 'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \\n[Clang 13.0.1 ]', 'platform': 'macOS-12.4-arm64-arm-64bit', 'event': 'saving'}\n",
            "INFO - 15:21:00: storing np array 'vectors' to word2vec.model.wv.vectors.npy\n",
            "INFO - 15:21:01: storing np array 'syn1neg' to word2vec.model.syn1neg.npy\n",
            "INFO - 15:21:01: not storing attribute cum_table\n",
            "INFO - 15:21:01: saved word2vec.model\n"
          ]
        }
      ],
      "source": [
        "w2v_model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh7lCKzXsPTe"
      },
      "source": [
        "Exporting preprocessed dataset for further steps (with replaced bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3URClcsfsPTe"
      },
      "outputs": [],
      "source": [
        "file_export = file_model.copy()\n",
        "file_export['old_text'] = file_export.text\n",
        "file_export.old_text = file_export.old_text.str.join(' ')\n",
        "file_export.text = file_export.text.apply(lambda x: ' '.join(bigram[x]))\n",
        "# file_export.rate = file_export.rate.astype('int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wdh0rMEsPTe"
      },
      "outputs": [],
      "source": [
        "file_export[['text', 'business_id','review_id']].to_csv('cleaned_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuDhN0P4sPTe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHgWgPwLsPTf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}